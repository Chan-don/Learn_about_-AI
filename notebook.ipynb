{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect memory to the chain.\n",
    "# LLM chain == off-the-shelf chain.\n",
    "# The off-the-shelf chain refer to general purpose chain. And this chain is very distributed in langchain.\n",
    "# off-the-shelf chain is quick to use. However, that cannot customize it.\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "# Upper Code is make llm model more specific.\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# last time we just write prompt text. So, This time we send message 'text' at Chat\n",
    "# 'MessagesPlaceholder' is show organize messages. Like, AI : ~~~~, Human : ~~~~.\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit= 120,\n",
    "    return_messages=True,\n",
    "    # Upper code mean do not change 'string'. Just use 'text'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    # 'ConversationSummaryBufferMemory' give message -> 'AI' -> 'Human' -> 'System'\n",
    "    # The MessagesPlaceholder intercept message and make many class.\n",
    "    # \"chat_history\" is no longer needed because the default memory key is \"History\"\n",
    "    # So, we can replace \"chat_history\" to \"history\"\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "def load_memory(_):\n",
    "    # '_' mean omit input code.\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "# Upper code is def for get memory variable\n",
    "# 'RunnablePassthrought.assign()' must take at least one argument. So, we need to enter input.\n",
    "# So, we give input in function, and print(input)\n",
    "\n",
    "chain = RunnablePassthrough.assign(history = load_memory) | prompt | llm\n",
    "# Upper code is make chain yourself.\n",
    "# When starting a chain. RunnablePassthrought.assign starts load_memory first, then prompts and then llm.\n",
    "# 'RunnablePassthrought' function allows you to use a function before the prompt is format.\n",
    "# And also, we can assign any value we want to that function 'history = load_memory'\n",
    "# And that variable is given to the prompt.\n",
    "# 'RunnablePassthrought.assign()' must take at least one argument. So, we need to enter input.\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\" : question})\n",
    "    # Last Code is passive management memory. So, we need management memory by automatic.\n",
    "    # So, we make def invoke_Chain function. JUST 'chain.invoke({\"question\" : ~~~})' is passive management memory. \n",
    "    memory.save_context({\"input\" : question}, {\"outputs\" : result.content})\n",
    "    # result.content mean 'AI' result.\n",
    "    print(result)\n",
    "\n",
    "# Add\n",
    "# The 'load_memory_varialbes' == load memory.\n",
    "# The 'save_context' == Save 'Human', 'AI' input, output context at memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Chandon! It's nice to meet you. How can I assist you today?\"\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Hello~! My name is Chandon!\")\n",
    "# This format is the value entered into the 'question' in the Upper code 'def invoke_chain(question).' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is Chandon!'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"And what is my name??\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
